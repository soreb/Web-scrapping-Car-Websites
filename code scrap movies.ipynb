{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from time import sleep\n",
    "from random import randint\n",
    "\n",
    "titles = []\n",
    "years = []\n",
    "time = []\n",
    "imdb_ratings = []\n",
    "metascores = []\n",
    "votes = []\n",
    "us_gross = []\n",
    "\n",
    "pages = np.arange(1, 1001, 50)\n",
    "\n",
    "for page in pages: \n",
    "\n",
    "  page = requests.get(\"https://www.imdb.com/search/title/?groups=top_1000&start=\" + str(page) + \"&ref_=adv_nxt\", headers=headers)\n",
    "\n",
    "  soup = BeautifulSoup(page.text, 'html.parser')\n",
    "  movie_div = soup.find_all('div', class_='lister-item mode-advanced')\n",
    "  \n",
    "  sleep(randint(2,10))\n",
    "\n",
    "  for container in movie_div:\n",
    "\n",
    "        name = container.h3.a.text\n",
    "        titles.append(name)\n",
    "        \n",
    "        year = container.h3.find('span', class_='lister-item-year').text\n",
    "        years.append(year)\n",
    "\n",
    "        runtime = container.p.find('span', class_='runtime') if container.p.find('span', class_='runtime') else ''\n",
    "        time.append(runtime)\n",
    "\n",
    "        imdb = float(container.strong.text)\n",
    "        imdb_ratings.append(imdb)\n",
    "\n",
    "        m_score = container.find('span', class_='metascore').text if container.find('span', class_='metascore') else ''\n",
    "        metascores.append(m_score)\n",
    "\n",
    "        nv = container.find_all('span', attrs={'name': 'nv'})\n",
    "        \n",
    "        vote = nv[0].text\n",
    "        votes.append(vote)\n",
    "        \n",
    "        grosses = nv[1].text if len(nv) > 1 else ''\n",
    "        us_gross.append(grosses)\n",
    "\n",
    "movies = pd.DataFrame({\n",
    "'movie': titles,\n",
    "'year': years,\n",
    "'imdb': imdb_ratings,\n",
    "'metascore': metascores,\n",
    "'votes': votes,\n",
    "'us_grossMillions': us_gross,\n",
    "'timeMin': time\n",
    "})\n",
    "\n",
    "movies['votes'] = movies['votes'].str.replace(',', '').astype(int)\n",
    "\n",
    "movies.loc[:, 'year'] = movies['year'].str[-5:-1].astype(int)\n",
    "\n",
    "movies['timeMin'] = movies['timeMin'].astype(str)\n",
    "movies['timeMin'] = movies['timeMin'].str.extract('(\\d+)').astype(int)\n",
    "\n",
    "movies['metascore'] = movies['metascore'].str.extract('(\\d+)')\n",
    "movies['metascore'] = pd.to_numeric(movies['metascore'], errors='coerce')\n",
    "\n",
    "movies['us_grossMillions'] = movies['us_grossMillions'].map(lambda x: x.lstrip('$').rstrip('M'))\n",
    "movies['us_grossMillions'] = pd.to_numeric(movies['us_grossMillions'], errors='coerce')\n",
    "\n",
    "\n",
    "# to see your dataframe\n",
    "print(movies)\n",
    "\n",
    "# to see the datatypes of your columns\n",
    "print(movies.dtypes)\n",
    "\n",
    "# to see where you're missing data and how much data is missing \n",
    "print(movies.isnull().sum())\n",
    "\n",
    "# to move all your scraped data to a CSV file\n",
    "movies.to_csv('movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
