{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scripting webscrap car offers\n",
    "### Source : https://www.youtube.com/watch?v=XQgXKtPSzUI&ab_channel=DataScienceDojo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as soup\n",
    "from urllib.request import urlopen as uReq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables, funcions, execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URl to web scrap from.\n",
    "# in this example we web scrap graphics cards from Newegg.com\n",
    "#page_url = \"https://www.otomoto.pl/osobowe/?search%5Border%5D=created_at_first%3Adesc&search%5Bbrand_program_id%5D%5B0%5D=&search%5Bcountry%5D=\"\n",
    "page_url = \"https://www.otomoto.pl/osobowe/?search%5Border%5D=created_at%3Adesc&page=1\"\n",
    "# opens the connection and downloads html page from url\n",
    "uClient = uReq(page_url)\n",
    "# uReq is the function urlopen from the module request that is in the package urllib\n",
    "# uReq will basically open the url and download all the content. So we save it in a variable\n",
    "# if I do a uClient.read() it will dump all the downloaded data, and it can crash the script.\n",
    "page_html = uClient.read()\n",
    "# parses html into a soup data structure to traverse html\n",
    "# as if it were a json data type.\n",
    "page_soup = soup(page_html, \"html.parser\")\n",
    "uClient.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_soup.h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finds each product from the store page\n",
    "containers = page_soup.findAll(\"div\", {\"class\": \"offer-item__content ds-details-container\"})\n",
    "len(containers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Vizualize the html script to have better vision\n",
    "#beautify the code thanks to external service: https://beautifier.io/\n",
    "container = containers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.otomoto.pl/oferta/mercedes-benz-klasa-e-e-300-de-biel-diamentowa-hybryda-rabat-143-500-pln-salon-pl-ID6Di8Ko.html#7ce9f71ee3'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grabs the URL\n",
    "container.div.h2.a[\"href\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mercedes-Benz Klasa E'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grabs the title within the (a) tag from title attribute\n",
    "# Then does proper casing using .title()\n",
    "# Then cleans the text of white space with strip()\n",
    "container.div.h2.a[\"title\"].title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# container.ul.li.span.text => it returns what I want but hard to target properly, so use findall\n",
    "\n",
    "# Grabs the text within the first \"(a)\" tag from within the list of queries.\n",
    "# use strip to clean up the space\n",
    "container.findAll(\"li\",{\"class\":\"ds-param\"})[0].text.strip() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'26252'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grabs the text within the Second \"(a)\" tag from within the list of queries.\n",
    "# use strip to clean up the space\n",
    "# Cleans the strip of (\"km\" and \" \") if it exists to just get number\n",
    "container.findAll(\"li\",{\"class\":\"ds-param\"})[1].text.strip().replace(\"km\", \"\").replace(\" \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1950'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grabs the text within the Third \"(a)\" tag from within the list of queries.\n",
    "# use strip to clean up the space\n",
    "# Cleans the strip of (\"cm3\" and \" \") if it exists to just get number\n",
    "container.findAll(\"li\",{\"class\":\"ds-param\"})[2].text.strip().replace(\"cm3\", \"\").replace(\" \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hybryda'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grabs the text within the Third \"(a)\" tag from within the list of queries.\n",
    "# use strip to clean up the space\n",
    "container.findAll(\"li\",{\"class\":\"ds-param\"})[3].text.strip() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'257700'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the price that is a span in the span\n",
    "# use strip to clean the space and remove empty space\n",
    "container.findAll(\"span\",{\"class\":\"offer-price__number ds-price-number\"})[0].span.text.strip().replace(\" \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Kraków'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "container.findAll(\"span\",{\"class\":\"ds-location-city\"})[0].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Małopolskie'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "container.findAll(\"span\",{\"class\":\"ds-location-region\"})[0].text.strip().replace(\"(\", \"\").replace(\")\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# name the output file to write to local disk\n",
    "out_filename = \"car_otomoto.csv\"\n",
    "# header of csv file to be written\n",
    "headers = \"car_name,price,year,mileage,engine_capacity,fuel_type,city,region \\n\"\n",
    "\n",
    "# opens file, and writes headers\n",
    "\n",
    "f = open(out_filename, \"w\", encoding=\"utf-8\")\n",
    "f.write(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finds each product from the store page\n",
    "containers = page_soup.findAll(\"div\", {\"class\": \"offer-item__content ds-details-container\"})\n",
    "len(containers)\n",
    "for containter in containers:\n",
    "    \n",
    "    url = container.div.h2.a[\"href\"]\n",
    "    car_name = container.div.h2.a[\"title\"].title()\n",
    "    price = container.findAll(\"span\",{\"class\":\"offer-price__number ds-price-number\"})[0].span.text.strip().replace(\" \", \"\")\n",
    "    year = container.findAll(\"li\",{\"class\":\"ds-param\"})[0].text.strip()\n",
    "    mileage = container.findAll(\"li\",{\"class\":\"ds-param\"})[1].text.strip().replace(\"km\", \"\").replace(\" \", \"\")\n",
    "    engine_capacity = container.findAll(\"li\",{\"class\":\"ds-param\"})[2].text.strip().replace(\"cm3\", \"\").replace(\" \", \"\")\n",
    "    fuel_type = container.findAll(\"li\",{\"class\":\"ds-param\"})[3].text.strip()\n",
    "    city = container.findAll(\"span\",{\"class\":\"ds-location-city\"})[0].text.strip()\n",
    "    region = container.findAll(\"span\",{\"class\":\"ds-location-region\"})[0].text.strip().replace(\"(\", \"\").replace(\")\", \"\")\n",
    "\n",
    "    # writes the dataset to file\n",
    "    f.write(url + \", \" + car_name.replace(\",\", \"|\") + \", \" + price + \", \" + year + \", \" + mileage + \", \" + engine_capacity + \", \" + fuel_type + \", \" + city + \", \" + region + \"\\n\")\n",
    "f.close()  # Close the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # parses html into a soup data structure to traverse html\n",
    "    # as if it were a json data type.\n",
    "#page_soup = soup(uClient.read(), \"html.parser\")\n",
    "#uClient.close()\n",
    "\n",
    "    # finds each product from the store page\n",
    "#containers = page_soup.findAll(\"div\", {\"class\": \"item-container\"})\n",
    "\n",
    "    # name the output file to write to local disk\n",
    "#out_filename = \"graphics_cards.csv\"\n",
    "# header of csv file to be written\n",
    "#headers = \"brand,product_name,shipping \\n\"\n",
    "\n",
    "    # opens file, and writes headers\n",
    "#f = open(out_filename, \"w\")\n",
    "#f.write(headers)\n",
    "\n",
    "    # loops over each product and grabs attributes about\n",
    "    # each product\n",
    "#for container in containers:\n",
    "    # Finds all link tags \"a\" from within the first div.\n",
    "        #make_rating_sp = container.div.select(\"a\")\n",
    "\n",
    "    # Grabs the title from the image title attribute\n",
    "    # Then does proper casing using .title()\n",
    "        #brand = make_rating_sp[0].img[\"title\"].title()\n",
    "\n",
    "    # Grabs the text within the second \"(a)\" tag from within\n",
    "    # the list of queries.\n",
    "        #product_name = container.div.select(\"a\")[2].text\n",
    "\n",
    "    # Grabs the product shipping information by searching\n",
    "    # all lists with the class \"price-ship\".\n",
    "    # Then cleans the text of white space with strip()\n",
    "    # Cleans the strip of \"Shipping $\" if it exists to just get number\n",
    "        #shipping = container.findAll(\"li\", {\"class\": \"price-ship\"})[0].text.strip().replace(\"$\", \"\").replace(\" Shipping\", \"\")\n",
    "\n",
    "    # prints the dataset to console\n",
    "        #print(\"brand: \" + brand + \"\\n\")\n",
    "        #print(\"product_name: \" + product_name + \"\\n\")\n",
    "        #print(\"shipping: \" + shipping + \"\\n\")\n",
    "\n",
    "    # writes the dataset to file\n",
    "        #f.write(brand + \", \" + product_name.replace(\",\", \"|\") + \", \" + shipping + \"\\n\")\n",
    "\n",
    "#f.close()  # Close the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
